{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ Rhythm Shah\n",
    "\n",
    "~ 1233960561\n",
    "\n",
    "~ 03/04/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 1 (5%) - Import Required Libraries and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary libraries for data processing, NLP, and interaction with LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:54:50.981723Z",
     "iopub.status.busy": "2025-03-05T20:54:50.981364Z",
     "iopub.status.idle": "2025-03-05T20:54:51.332656Z",
     "shell.execute_reply": "2025-03-05T20:54:51.332123Z",
     "shell.execute_reply.started": "2025-03-05T20:54:50.981701Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import json\n",
    "import boto3\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load restaurant_reviews_az.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:54:53.608489Z",
     "iopub.status.busy": "2025-03-05T20:54:53.607892Z",
     "iopub.status.idle": "2025-03-05T20:54:53.983874Z",
     "shell.execute_reply": "2025-03-05T20:54:53.983351Z",
     "shell.execute_reply.started": "2025-03-05T20:54:53.608470Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('restaurant_reviews_az.csv')[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:54:54.007280Z",
     "iopub.status.busy": "2025-03-05T20:54:54.007035Z",
     "iopub.status.idle": "2025-03-05T20:54:54.012348Z",
     "shell.execute_reply": "2025-03-05T20:54:54.011949Z",
     "shell.execute_reply.started": "2025-03-05T20:54:54.007262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 2 (5%) - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T08:09:15.593285Z",
     "iopub.status.busy": "2025-03-05T08:09:15.592859Z",
     "iopub.status.idle": "2025-03-05T08:09:15.596805Z",
     "shell.execute_reply": "2025-03-05T08:09:15.596083Z",
     "shell.execute_reply.started": "2025-03-05T08:09:15.593264Z"
    }
   },
   "source": [
    "## Remove 3-star reviews from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:54:55.420239Z",
     "iopub.status.busy": "2025-03-05T20:54:55.419978Z",
     "iopub.status.idle": "2025-03-05T20:54:55.430804Z",
     "shell.execute_reply": "2025-03-05T20:54:55.430272Z",
     "shell.execute_reply.started": "2025-03-05T20:54:55.420221Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['stars'] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new column Sentiment where:\n",
    "Reviews with 1 or 2 stars are labeled as 0 (Negative Sentiment).\n",
    "Reviews with 4 or 5 stars are labeled as 1 (Positive Sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:54:57.037334Z",
     "iopub.status.busy": "2025-03-05T20:54:57.037062Z",
     "iopub.status.idle": "2025-03-05T20:54:57.042212Z",
     "shell.execute_reply": "2025-03-05T20:54:57.041538Z",
     "shell.execute_reply.started": "2025-03-05T20:54:57.037316Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['stars'].apply(lambda x: 1 if x >= 4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset for this assignment by randomly selecting 50 positive reviews and 50 negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:54:58.729566Z",
     "iopub.status.busy": "2025-03-05T20:54:58.729285Z",
     "iopub.status.idle": "2025-03-05T20:54:58.742721Z",
     "shell.execute_reply": "2025-03-05T20:54:58.742222Z",
     "shell.execute_reply.started": "2025-03-05T20:54:58.729549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ofwKw-0z09_MtZG4L91-Eg</td>\n",
       "      <td>lOWLsQUsWhXzNnctHzOAaw</td>\n",
       "      <td>3YERGr7UbpSpddqL0Eiu5g</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great staff and wonderful food. Great prices. ...</td>\n",
       "      <td>2021-07-03 21:33:56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0Es1Xy_bdxHbDDwgJ_fS7Q</td>\n",
       "      <td>h-tdiniXt8ymH7HfdIJibw</td>\n",
       "      <td>8QJTzIaR5FceGds8HBSIig</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Solid 4 stars...\\nI've had these beers around ...</td>\n",
       "      <td>2020-12-28 01:07:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JGvlW20ZQiqcvgrZ3Fo2_g</td>\n",
       "      <td>GBe3Jhc4bdElfh5LvO-_BA</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is set up as a buffet, it's your ty...</td>\n",
       "      <td>2021-02-26 00:35:08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jEb0nFqnFmi0oXwXlLkuDw</td>\n",
       "      <td>3_iu3Mh30tNU7BcKW-4ZfA</td>\n",
       "      <td>xHdekRjTK93GR2AgtvrtgQ</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Met up with prior boss and hadn't been here si...</td>\n",
       "      <td>2021-06-24 23:39:12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20K-rfUeeG5gOjToa8fDNw</td>\n",
       "      <td>lx0tLhpSCjJ6sQBOy6KpzQ</td>\n",
       "      <td>B10mqANgHvL8gBteo1UhAA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Our waiter was named Lee, he was very attentiv...</td>\n",
       "      <td>2020-07-11 21:23:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  ofwKw-0z09_MtZG4L91-Eg  lOWLsQUsWhXzNnctHzOAaw  3YERGr7UbpSpddqL0Eiu5g   \n",
       "1  0Es1Xy_bdxHbDDwgJ_fS7Q  h-tdiniXt8ymH7HfdIJibw  8QJTzIaR5FceGds8HBSIig   \n",
       "2  JGvlW20ZQiqcvgrZ3Fo2_g  GBe3Jhc4bdElfh5LvO-_BA  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  jEb0nFqnFmi0oXwXlLkuDw  3_iu3Mh30tNU7BcKW-4ZfA  xHdekRjTK93GR2AgtvrtgQ   \n",
       "4  20K-rfUeeG5gOjToa8fDNw  lx0tLhpSCjJ6sQBOy6KpzQ  B10mqANgHvL8gBteo1UhAA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       0      0     0   \n",
       "1      4       1      0     0   \n",
       "2      4       0      0     0   \n",
       "3      4       3      0     2   \n",
       "4      5       1      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Great staff and wonderful food. Great prices. ...  2021-07-03 21:33:56   \n",
       "1  Solid 4 stars...\\nI've had these beers around ...  2020-12-28 01:07:27   \n",
       "2  This place is set up as a buffet, it's your ty...  2021-02-26 00:35:08   \n",
       "3  Met up with prior boss and hadn't been here si...  2021-06-24 23:39:12   \n",
       "4  Our waiter was named Lee, he was very attentiv...  2020-07-11 21:23:41   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews = df[df['Sentiment'] == 1].sample(n=50)\n",
    "negative_reviews = df[df['Sentiment'] == 0].sample(n=50)\n",
    "\n",
    "df1 = pd.concat([positive_reviews, negative_reviews]).reset_index(drop=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:55:00.463948Z",
     "iopub.status.busy": "2025-03-05T20:55:00.463683Z",
     "iopub.status.idle": "2025-03-05T20:55:00.467524Z",
     "shell.execute_reply": "2025-03-05T20:55:00.467072Z",
     "shell.execute_reply.started": "2025-03-05T20:55:00.463931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 3 (20%) - Perform Sentiment Analysis Using Zero-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T08:11:09.610991Z",
     "iopub.status.busy": "2025-03-05T08:11:09.610516Z",
     "iopub.status.idle": "2025-03-05T08:11:09.614330Z",
     "shell.execute_reply": "2025-03-05T08:11:09.613741Z",
     "shell.execute_reply.started": "2025-03-05T08:11:09.610966Z"
    }
   },
   "source": [
    "## Use a Claude 3 Sonnet for zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:55:02.166671Z",
     "iopub.status.busy": "2025-03-05T20:55:02.166311Z",
     "iopub.status.idle": "2025-03-05T20:55:02.219029Z",
     "shell.execute_reply": "2025-03-05T20:55:02.218564Z",
     "shell.execute_reply.started": "2025-03-05T20:55:02.166652Z"
    }
   },
   "outputs": [],
   "source": [
    "client = boto3.client(\"bedrock-runtime\", region_name = \"us-east-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment labels for the selected 100 reviews without providing any labeled training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:03:21.598674Z",
     "iopub.status.busy": "2025-03-05T21:03:21.598276Z",
     "iopub.status.idle": "2025-03-05T21:03:21.603539Z",
     "shell.execute_reply": "2025-03-05T21:03:21.603010Z",
     "shell.execute_reply.started": "2025-03-05T21:03:21.598655Z"
    }
   },
   "outputs": [],
   "source": [
    "def LLM(data, model_id):\n",
    "    results = []\n",
    "\n",
    "    for i in data:\n",
    "        messages = [{\"role\": \"user\", \"content\": f\"In only one word classify the sentiment of '{i}' into either Positive or Negative only. Do not use any other words such as neutral for classification. Use only Positive or Negative\"}]\n",
    "\n",
    "        request_body = {\"anthropic_version\": \"bedrock-2023-05-31\", \"messages\": messages, \"max_tokens\": 512, \"temperature\": 0.1, \"top_p\": 1.0}\n",
    "\n",
    "        try:\n",
    "            response = client.invoke_model(modelId = model_id, contentType = 'application/json', body = json.dumps(request_body))\n",
    "            result = json.loads(response['body'].read().decode())\n",
    "            sentiment = result['content'][0]['text'].strip()\n",
    "            results.append(sentiment)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text '{i}': {e}\")\n",
    "            results.append(\"Error\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a general code which is flexible to different models. I just need to pass the model id in the function parameter along with the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:55:04.807446Z",
     "iopub.status.busy": "2025-03-05T20:55:04.807174Z",
     "iopub.status.idle": "2025-03-05T20:56:00.743414Z",
     "shell.execute_reply": "2025-03-05T20:56:00.742765Z",
     "shell.execute_reply.started": "2025-03-05T20:55:04.807428Z"
    }
   },
   "outputs": [],
   "source": [
    "Claude3 = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "df1['Claude3_Prediction'] = LLM(df1['text'], Claude3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:56:00.744673Z",
     "iopub.status.busy": "2025-03-05T20:56:00.744354Z",
     "iopub.status.idle": "2025-03-05T20:56:00.753604Z",
     "shell.execute_reply": "2025-03-05T20:56:00.753132Z",
     "shell.execute_reply.started": "2025-03-05T20:56:00.744652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Claude3_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ofwKw-0z09_MtZG4L91-Eg</td>\n",
       "      <td>lOWLsQUsWhXzNnctHzOAaw</td>\n",
       "      <td>3YERGr7UbpSpddqL0Eiu5g</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great staff and wonderful food. Great prices. ...</td>\n",
       "      <td>2021-07-03 21:33:56</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0Es1Xy_bdxHbDDwgJ_fS7Q</td>\n",
       "      <td>h-tdiniXt8ymH7HfdIJibw</td>\n",
       "      <td>8QJTzIaR5FceGds8HBSIig</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Solid 4 stars...\\nI've had these beers around ...</td>\n",
       "      <td>2020-12-28 01:07:27</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JGvlW20ZQiqcvgrZ3Fo2_g</td>\n",
       "      <td>GBe3Jhc4bdElfh5LvO-_BA</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is set up as a buffet, it's your ty...</td>\n",
       "      <td>2021-02-26 00:35:08</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jEb0nFqnFmi0oXwXlLkuDw</td>\n",
       "      <td>3_iu3Mh30tNU7BcKW-4ZfA</td>\n",
       "      <td>xHdekRjTK93GR2AgtvrtgQ</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Met up with prior boss and hadn't been here si...</td>\n",
       "      <td>2021-06-24 23:39:12</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20K-rfUeeG5gOjToa8fDNw</td>\n",
       "      <td>lx0tLhpSCjJ6sQBOy6KpzQ</td>\n",
       "      <td>B10mqANgHvL8gBteo1UhAA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Our waiter was named Lee, he was very attentiv...</td>\n",
       "      <td>2020-07-11 21:23:41</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  ofwKw-0z09_MtZG4L91-Eg  lOWLsQUsWhXzNnctHzOAaw  3YERGr7UbpSpddqL0Eiu5g   \n",
       "1  0Es1Xy_bdxHbDDwgJ_fS7Q  h-tdiniXt8ymH7HfdIJibw  8QJTzIaR5FceGds8HBSIig   \n",
       "2  JGvlW20ZQiqcvgrZ3Fo2_g  GBe3Jhc4bdElfh5LvO-_BA  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  jEb0nFqnFmi0oXwXlLkuDw  3_iu3Mh30tNU7BcKW-4ZfA  xHdekRjTK93GR2AgtvrtgQ   \n",
       "4  20K-rfUeeG5gOjToa8fDNw  lx0tLhpSCjJ6sQBOy6KpzQ  B10mqANgHvL8gBteo1UhAA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       0      0     0   \n",
       "1      4       1      0     0   \n",
       "2      4       0      0     0   \n",
       "3      4       3      0     2   \n",
       "4      5       1      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Great staff and wonderful food. Great prices. ...  2021-07-03 21:33:56   \n",
       "1  Solid 4 stars...\\nI've had these beers around ...  2020-12-28 01:07:27   \n",
       "2  This place is set up as a buffet, it's your ty...  2021-02-26 00:35:08   \n",
       "3  Met up with prior boss and hadn't been here si...  2021-06-24 23:39:12   \n",
       "4  Our waiter was named Lee, he was very attentiv...  2020-07-11 21:23:41   \n",
       "\n",
       "   Sentiment Claude3_Prediction  \n",
       "0          1           Positive  \n",
       "1          1           Positive  \n",
       "2          1           Positive  \n",
       "3          1           Positive  \n",
       "4          1           Positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:56:05.622878Z",
     "iopub.status.busy": "2025-03-05T20:56:05.622595Z",
     "iopub.status.idle": "2025-03-05T20:56:05.629444Z",
     "shell.execute_reply": "2025-03-05T20:56:05.628927Z",
     "shell.execute_reply.started": "2025-03-05T20:56:05.622858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_Prediction\n",
       "Positive    51\n",
       "Negative    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Claude3_Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance using precision, recall, f1, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:56:07.878819Z",
     "iopub.status.busy": "2025-03-05T20:56:07.878534Z",
     "iopub.status.idle": "2025-03-05T20:56:07.883728Z",
     "shell.execute_reply": "2025-03-05T20:56:07.883127Z",
     "shell.execute_reply.started": "2025-03-05T20:56:07.878783Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model_performance(pred_col, true_col = \"Sentiment\"):\n",
    "    y_true = df1[true_col]\n",
    "    y_pred = df1[pred_col].map({\"Positive\": 1, \"Negative\": 0})\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a general code for calculate the model metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:56:09.073555Z",
     "iopub.status.busy": "2025-03-05T20:56:09.073287Z",
     "iopub.status.idle": "2025-03-05T20:56:09.086976Z",
     "shell.execute_reply": "2025-03-05T20:56:09.086071Z",
     "shell.execute_reply.started": "2025-03-05T20:56:09.073537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.00%\n",
      "Precision: 0.96\n",
      "Recall: 0.98\n",
      "F1-Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 4 (20%) - Perform Sentiment Analysis Using Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a few examples for few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:56:32.903573Z",
     "iopub.status.busy": "2025-03-05T20:56:32.903250Z",
     "iopub.status.idle": "2025-03-05T20:56:32.906715Z",
     "shell.execute_reply": "2025-03-05T20:56:32.906176Z",
     "shell.execute_reply.started": "2025-03-05T20:56:32.903552Z"
    }
   },
   "outputs": [],
   "source": [
    "few_shot_prefix = \"\"\"\n",
    "Examples:\n",
    "1. \"Amazing food, great service!\" -> Positive\n",
    "2. \"Terrible experience, rude staff.\" -> Negative\n",
    "3. \"It was okay, nothing special.\" -> Positive\n",
    "4. \"Slow delivery, cold meal.\" -> Negative\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:04:07.008518Z",
     "iopub.status.busy": "2025-03-05T09:04:07.008043Z",
     "iopub.status.idle": "2025-03-05T09:04:07.011505Z",
     "shell.execute_reply": "2025-03-05T09:04:07.010978Z",
     "shell.execute_reply.started": "2025-03-05T09:04:07.008495Z"
    }
   },
   "source": [
    "## Use the example(s) to guide the LLM in classifying sentiment for the selected 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:03:29.123182Z",
     "iopub.status.busy": "2025-03-05T21:03:29.122871Z",
     "iopub.status.idle": "2025-03-05T21:04:32.839553Z",
     "shell.execute_reply": "2025-03-05T21:04:32.838766Z",
     "shell.execute_reply.started": "2025-03-05T21:03:29.123162Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['Claude3_FewShot_Prediction'] = LLM(few_shot_prefix + df1['text'], Claude3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:04:32.840799Z",
     "iopub.status.busy": "2025-03-05T21:04:32.840484Z",
     "iopub.status.idle": "2025-03-05T21:04:32.846116Z",
     "shell.execute_reply": "2025-03-05T21:04:32.845662Z",
     "shell.execute_reply.started": "2025-03-05T21:04:32.840779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_FewShot_Prediction\n",
       "Positive    51\n",
       "Negative    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Claude3_FewShot_Prediction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance using precision, recall, f1, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:04:40.211745Z",
     "iopub.status.busy": "2025-03-05T21:04:40.211444Z",
     "iopub.status.idle": "2025-03-05T21:04:40.222797Z",
     "shell.execute_reply": "2025-03-05T21:04:40.222275Z",
     "shell.execute_reply.started": "2025-03-05T21:04:40.211726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.00%\n",
      "Precision: 0.96\n",
      "Recall: 0.98\n",
      "F1-Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_FewShot_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 5 (20%) - Experiment with Multiple LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checking for working models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:06:16.943543Z",
     "iopub.status.busy": "2025-03-05T20:06:16.943112Z",
     "iopub.status.idle": "2025-03-05T20:06:17.036222Z",
     "shell.execute_reply": "2025-03-05T20:06:17.035699Z",
     "shell.execute_reply.started": "2025-03-05T20:06:16.943523Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Titan Text Large, Model ID: amazon.titan-tg1-large, Provider: Amazon\n",
      "Model Name: Titan Image Generator G1, Model ID: amazon.titan-image-generator-v1:0, Provider: Amazon\n",
      "Model Name: Titan Image Generator G1, Model ID: amazon.titan-image-generator-v1, Provider: Amazon\n",
      "Model Name: Titan Image Generator G1 v2, Model ID: amazon.titan-image-generator-v2:0, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Premier, Model ID: amazon.titan-text-premier-v1:0, Provider: Amazon\n",
      "Model Name: Nova Pro, Model ID: amazon.nova-pro-v1:0:300k, Provider: Amazon\n",
      "Model Name: Nova Pro, Model ID: amazon.nova-pro-v1:0, Provider: Amazon\n",
      "Model Name: Nova Lite, Model ID: amazon.nova-lite-v1:0:300k, Provider: Amazon\n",
      "Model Name: Nova Lite, Model ID: amazon.nova-lite-v1:0, Provider: Amazon\n",
      "Model Name: Nova Canvas, Model ID: amazon.nova-canvas-v1:0, Provider: Amazon\n",
      "Model Name: Nova Reel, Model ID: amazon.nova-reel-v1:0, Provider: Amazon\n",
      "Model Name: Nova Micro, Model ID: amazon.nova-micro-v1:0:128k, Provider: Amazon\n",
      "Model Name: Nova Micro, Model ID: amazon.nova-micro-v1:0, Provider: Amazon\n",
      "Model Name: Titan Text Embeddings v2, Model ID: amazon.titan-embed-g1-text-02, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Lite, Model ID: amazon.titan-text-lite-v1:0:4k, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Lite, Model ID: amazon.titan-text-lite-v1, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Express, Model ID: amazon.titan-text-express-v1:0:8k, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Express, Model ID: amazon.titan-text-express-v1, Provider: Amazon\n",
      "Model Name: Titan Embeddings G1 - Text, Model ID: amazon.titan-embed-text-v1:2:8k, Provider: Amazon\n",
      "Model Name: Titan Embeddings G1 - Text, Model ID: amazon.titan-embed-text-v1, Provider: Amazon\n",
      "Model Name: Titan Text Embeddings V2, Model ID: amazon.titan-embed-text-v2:0:8k, Provider: Amazon\n",
      "Model Name: Titan Text Embeddings V2, Model ID: amazon.titan-embed-text-v2:0, Provider: Amazon\n",
      "Model Name: Titan Multimodal Embeddings G1, Model ID: amazon.titan-embed-image-v1:0, Provider: Amazon\n",
      "Model Name: Titan Multimodal Embeddings G1, Model ID: amazon.titan-embed-image-v1, Provider: Amazon\n",
      "Model Name: SDXL 1.0, Model ID: stability.stable-diffusion-xl-v1:0, Provider: Stability AI\n",
      "Model Name: SDXL 1.0, Model ID: stability.stable-diffusion-xl-v1, Provider: Stability AI\n",
      "Model Name: J2 Grande Instruct, Model ID: ai21.j2-grande-instruct, Provider: AI21 Labs\n",
      "Model Name: J2 Jumbo Instruct, Model ID: ai21.j2-jumbo-instruct, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Mid, Model ID: ai21.j2-mid, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Mid, Model ID: ai21.j2-mid-v1, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Ultra, Model ID: ai21.j2-ultra, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Ultra, Model ID: ai21.j2-ultra-v1:0:8k, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Ultra, Model ID: ai21.j2-ultra-v1, Provider: AI21 Labs\n",
      "Model Name: Jamba-Instruct, Model ID: ai21.jamba-instruct-v1:0, Provider: AI21 Labs\n",
      "Model Name: Jamba 1.5 Large, Model ID: ai21.jamba-1-5-large-v1:0, Provider: AI21 Labs\n",
      "Model Name: Jamba 1.5 Mini, Model ID: ai21.jamba-1-5-mini-v1:0, Provider: AI21 Labs\n",
      "Model Name: Claude Instant, Model ID: anthropic.claude-instant-v1:2:100k, Provider: Anthropic\n",
      "Model Name: Claude Instant, Model ID: anthropic.claude-instant-v1, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:0:18k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:0:100k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:1:18k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:1:200k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:1, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2, Provider: Anthropic\n",
      "Model Name: Claude 3 Sonnet, Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k, Provider: Anthropic\n",
      "Model Name: Claude 3 Sonnet, Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k, Provider: Anthropic\n",
      "Model Name: Claude 3 Sonnet, Model ID: anthropic.claude-3-sonnet-20240229-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3 Haiku, Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k, Provider: Anthropic\n",
      "Model Name: Claude 3 Haiku, Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k, Provider: Anthropic\n",
      "Model Name: Claude 3 Haiku, Model ID: anthropic.claude-3-haiku-20240307-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0:12k, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0:28k, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0:200k, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3.5 Sonnet, Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3.5 Sonnet v2, Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0, Provider: Anthropic\n",
      "Model Name: Claude 3.7 Sonnet, Model ID: anthropic.claude-3-7-sonnet-20250219-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3.5 Haiku, Model ID: anthropic.claude-3-5-haiku-20241022-v1:0, Provider: Anthropic\n",
      "Model Name: Command, Model ID: cohere.command-text-v14:7:4k, Provider: Cohere\n",
      "Model Name: Command, Model ID: cohere.command-text-v14, Provider: Cohere\n",
      "Model Name: Command R, Model ID: cohere.command-r-v1:0, Provider: Cohere\n",
      "Model Name: Command R+, Model ID: cohere.command-r-plus-v1:0, Provider: Cohere\n",
      "Model Name: Command Light, Model ID: cohere.command-light-text-v14:7:4k, Provider: Cohere\n",
      "Model Name: Command Light, Model ID: cohere.command-light-text-v14, Provider: Cohere\n",
      "Model Name: Embed English, Model ID: cohere.embed-english-v3:0:512, Provider: Cohere\n",
      "Model Name: Embed English, Model ID: cohere.embed-english-v3, Provider: Cohere\n",
      "Model Name: Embed Multilingual, Model ID: cohere.embed-multilingual-v3:0:512, Provider: Cohere\n",
      "Model Name: Embed Multilingual, Model ID: cohere.embed-multilingual-v3, Provider: Cohere\n",
      "Model Name: Llama 3 8B Instruct, Model ID: meta.llama3-8b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3 70B Instruct, Model ID: meta.llama3-70b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.1 8B Instruct, Model ID: meta.llama3-1-8b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.1 70B Instruct, Model ID: meta.llama3-1-70b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 11B Instruct, Model ID: meta.llama3-2-11b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 90B Instruct, Model ID: meta.llama3-2-90b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 1B Instruct, Model ID: meta.llama3-2-1b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 3B Instruct, Model ID: meta.llama3-2-3b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.3 70B Instruct, Model ID: meta.llama3-3-70b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Mistral 7B Instruct, Model ID: mistral.mistral-7b-instruct-v0:2, Provider: Mistral AI\n",
      "Model Name: Mixtral 8x7B Instruct, Model ID: mistral.mixtral-8x7b-instruct-v0:1, Provider: Mistral AI\n",
      "Model Name: Mistral Large (24.02), Model ID: mistral.mistral-large-2402-v1:0, Provider: Mistral AI\n",
      "Model Name: Mistral Small (24.02), Model ID: mistral.mistral-small-2402-v1:0, Provider: Mistral AI\n"
     ]
    }
   ],
   "source": [
    "bedrock = boto3.client('bedrock', region_name='us-east-1')\n",
    "response = bedrock.list_foundation_models()\n",
    "\n",
    "for model in response['modelSummaries']:\n",
    "    print(f\"Model Name: {model['modelName']}, Model ID: {model['modelId']}, Provider: {model['providerName']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:19:13.455387Z",
     "iopub.status.busy": "2025-03-05T20:19:13.455125Z",
     "iopub.status.idle": "2025-03-05T20:19:16.870479Z",
     "shell.execute_reply": "2025-03-05T20:19:16.869956Z",
     "shell.execute_reply.started": "2025-03-05T20:19:13.455369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Bedrock Models (March 5, 2025):\n",
      "--------------------------------------------------------------------------------\n",
      "Model: Titan Text Large          | ID: amazon.titan-tg1-large                   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Image Generator G1  | ID: amazon.titan-image-generator-v1:0        | Status: Skipped    | Details: Image generation model, not applicable for text sentiment\n",
      "Model: Titan Image Generator G1  | ID: amazon.titan-image-generator-v1          | Status: Skipped    | Details: Image generation model, not applicable for text sentiment\n",
      "Model: Titan Image Generator G1 v2 | ID: amazon.titan-image-generator-v2:0        | Status: Skipped    | Details: Image generation model, not applicable for text sentiment\n",
      "Model: Titan Text G1 - Premier   | ID: amazon.titan-text-premier-v1:0           | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Pro                  | ID: amazon.nova-pro-v1:0:300k                | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Nova Pro                  | ID: amazon.nova-pro-v1:0                     | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Lite                 | ID: amazon.nova-lite-v1:0:300k               | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Nova Lite                 | ID: amazon.nova-lite-v1:0                    | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Canvas               | ID: amazon.nova-canvas-v1:0                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Reel                 | ID: amazon.nova-reel-v1:0                    | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: This action doesn't support the model that you provided. Try again with a supported text or chat model.\n",
      "Model: Nova Micro                | ID: amazon.nova-micro-v1:0:128k              | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Nova Micro                | ID: amazon.nova-micro-v1:0                   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text Embeddings v2  | ID: amazon.titan-embed-g1-text-02            | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text G1 - Lite      | ID: amazon.titan-text-lite-v1:0:4k           | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Text G1 - Lite      | ID: amazon.titan-text-lite-v1                | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text G1 - Express   | ID: amazon.titan-text-express-v1:0:8k        | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Text G1 - Express   | ID: amazon.titan-text-express-v1             | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Embeddings G1 - Text | ID: amazon.titan-embed-text-v1:2:8k          | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Embeddings G1 - Text | ID: amazon.titan-embed-text-v1               | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text Embeddings V2  | ID: amazon.titan-embed-text-v2:0:8k          | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Text Embeddings V2  | ID: amazon.titan-embed-text-v2:0             | Status: Skipped    | Details: Embedding model, not applicable for sentiment\n",
      "Model: Titan Multimodal Embeddings G1 | ID: amazon.titan-embed-image-v1:0            | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model doesn't support on-demand throughput.\n",
      "Model: Titan Multimodal Embeddings G1 | ID: amazon.titan-embed-image-v1              | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: SDXL 1.0                  | ID: stability.stable-diffusion-xl-v1:0       | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model doesn't support on-demand throughput.\n",
      "Model: SDXL 1.0                  | ID: stability.stable-diffusion-xl-v1         | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: J2 Grande Instruct        | ID: ai21.j2-grande-instruct                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: J2 Jumbo Instruct         | ID: ai21.j2-jumbo-instruct                   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Mid            | ID: ai21.j2-mid                              | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Mid            | ID: ai21.j2-mid-v1                           | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Ultra          | ID: ai21.j2-ultra                            | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Ultra          | ID: ai21.j2-ultra-v1:0:8k                    | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Jurassic-2 Ultra          | ID: ai21.j2-ultra-v1                         | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jamba-Instruct            | ID: ai21.jamba-instruct-v1:0                 | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jamba 1.5 Large           | ID: ai21.jamba-1-5-large-v1:0                | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jamba 1.5 Mini            | ID: ai21.jamba-1-5-mini-v1:0                 | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude Instant            | ID: anthropic.claude-instant-v1:2:100k       | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude Instant            | ID: anthropic.claude-instant-v1              | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:0:18k                | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:0:100k               | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:1:18k                | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:1:200k               | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:1                    | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude                    | ID: anthropic.claude-v2                      | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude 3 Sonnet           | ID: anthropic.claude-3-sonnet-20240229-v1:0:28k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Sonnet           | ID: anthropic.claude-3-sonnet-20240229-v1:0:200k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Sonnet           | ID: anthropic.claude-3-sonnet-20240229-v1:0  | Status: Success    | Details: Positive\n",
      "Model: Claude 3 Haiku            | ID: anthropic.claude-3-haiku-20240307-v1:0:48k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Haiku            | ID: anthropic.claude-3-haiku-20240307-v1:0:200k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Haiku            | ID: anthropic.claude-3-haiku-20240307-v1:0   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0:12k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0:28k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0:200k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0    | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-opus-20240229-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Claude 3.5 Sonnet         | ID: anthropic.claude-3-5-sonnet-20240620-v1:0 | Status: Success    | Details: Positive\n",
      "Model: Claude 3.5 Sonnet v2      | ID: anthropic.claude-3-5-sonnet-20241022-v2:0 | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-5-sonnet-20241022-v2:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Claude 3.7 Sonnet         | ID: anthropic.claude-3-7-sonnet-20250219-v1:0 | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-7-sonnet-20250219-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Claude 3.5 Haiku          | ID: anthropic.claude-3-5-haiku-20241022-v1:0 | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-5-haiku-20241022-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Command                   | ID: cohere.command-text-v14:7:4k             | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Command                   | ID: cohere.command-text-v14                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Command R                 | ID: cohere.command-r-v1:0                    | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Command R+                | ID: cohere.command-r-plus-v1:0               | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Command Light             | ID: cohere.command-light-text-v14:7:4k       | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Command Light             | ID: cohere.command-light-text-v14            | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Embed English             | ID: cohere.embed-english-v3:0:512            | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Embed English             | ID: cohere.embed-english-v3                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Embed Multilingual        | ID: cohere.embed-multilingual-v3:0:512       | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Embed Multilingual        | ID: cohere.embed-multilingual-v3             | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Llama 3 8B Instruct       | ID: meta.llama3-8b-instruct-v1:0             | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Llama 3 70B Instruct      | ID: meta.llama3-70b-instruct-v1:0            | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: #: extraneous key [max_tokens] is not permitted, please reformat your input and try again.\n",
      "Model: Llama 3.1 8B Instruct     | ID: meta.llama3-1-8b-instruct-v1:0           | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-1-8b-instruct-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.1 70B Instruct    | ID: meta.llama3-1-70b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-1-70b-instruct-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 11B Instruct    | ID: meta.llama3-2-11b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-11b-instruct-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 90B Instruct    | ID: meta.llama3-2-90b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-90b-instruct-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 1B Instruct     | ID: meta.llama3-2-1b-instruct-v1:0           | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-1b-instruct-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 3B Instruct     | ID: meta.llama3-2-3b-instruct-v1:0           | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-3b-instruct-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.3 70B Instruct    | ID: meta.llama3-3-70b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-3-70b-instruct-v1:0 with on-demand throughput isnt supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Mistral 7B Instruct       | ID: mistral.mistral-7b-instruct-v0:2         | Status: Invalid    | Details: Unexpected output: Unknown\n",
      "Model: Mixtral 8x7B Instruct     | ID: mistral.mixtral-8x7b-instruct-v0:1       | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Mistral Large (24.02)     | ID: mistral.mistral-large-2402-v1:0          | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Mistral Small (24.02)     | ID: mistral.mistral-small-2402-v1:0          | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Models working:\n",
      "['Claude 3 Sonnet', 'Claude 3.5 Sonnet']\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bedrock client\n",
    "client = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "# Full list of models from your input\n",
    "models_to_test = [\n",
    "    {\"name\": \"Titan Text Large\", \"id\": \"amazon.titan-tg1-large\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Image Generator G1\", \"id\": \"amazon.titan-image-generator-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Image Generator G1\", \"id\": \"amazon.titan-image-generator-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Image Generator G1 v2\", \"id\": \"amazon.titan-image-generator-v2:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Premier\", \"id\": \"amazon.titan-text-premier-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Pro\", \"id\": \"amazon.nova-pro-v1:0:300k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Pro\", \"id\": \"amazon.nova-pro-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Lite\", \"id\": \"amazon.nova-lite-v1:0:300k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Lite\", \"id\": \"amazon.nova-lite-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Canvas\", \"id\": \"amazon.nova-canvas-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Reel\", \"id\": \"amazon.nova-reel-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Micro\", \"id\": \"amazon.nova-micro-v1:0:128k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Micro\", \"id\": \"amazon.nova-micro-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text Embeddings v2\", \"id\": \"amazon.titan-embed-g1-text-02\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Lite\", \"id\": \"amazon.titan-text-lite-v1:0:4k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Lite\", \"id\": \"amazon.titan-text-lite-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Express\", \"id\": \"amazon.titan-text-express-v1:0:8k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Express\", \"id\": \"amazon.titan-text-express-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Embeddings G1 - Text\", \"id\": \"amazon.titan-embed-text-v1:2:8k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Embeddings G1 - Text\", \"id\": \"amazon.titan-embed-text-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text Embeddings V2\", \"id\": \"amazon.titan-embed-text-v2:0:8k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text Embeddings V2\", \"id\": \"amazon.titan-embed-text-v2:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Multimodal Embeddings G1\", \"id\": \"amazon.titan-embed-image-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Multimodal Embeddings G1\", \"id\": \"amazon.titan-embed-image-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"SDXL 1.0\", \"id\": \"stability.stable-diffusion-xl-v1:0\", \"provider\": \"Stability AI\"},\n",
    "    {\"name\": \"SDXL 1.0\", \"id\": \"stability.stable-diffusion-xl-v1\", \"provider\": \"Stability AI\"},\n",
    "    {\"name\": \"J2 Grande Instruct\", \"id\": \"ai21.j2-grande-instruct\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"J2 Jumbo Instruct\", \"id\": \"ai21.j2-jumbo-instruct\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Mid\", \"id\": \"ai21.j2-mid\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Mid\", \"id\": \"ai21.j2-mid-v1\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Ultra\", \"id\": \"ai21.j2-ultra\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Ultra\", \"id\": \"ai21.j2-ultra-v1:0:8k\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Ultra\", \"id\": \"ai21.j2-ultra-v1\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jamba-Instruct\", \"id\": \"ai21.jamba-instruct-v1:0\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jamba 1.5 Large\", \"id\": \"ai21.jamba-1-5-large-v1:0\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jamba 1.5 Mini\", \"id\": \"ai21.jamba-1-5-mini-v1:0\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Claude Instant\", \"id\": \"anthropic.claude-instant-v1:2:100k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude Instant\", \"id\": \"anthropic.claude-instant-v1\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:0:18k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:0:100k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:1:18k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:1:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:1\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Sonnet\", \"id\": \"anthropic.claude-3-sonnet-20240229-v1:0:28k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Sonnet\", \"id\": \"anthropic.claude-3-sonnet-20240229-v1:0:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Sonnet\", \"id\": \"anthropic.claude-3-sonnet-20240229-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Haiku\", \"id\": \"anthropic.claude-3-haiku-20240307-v1:0:48k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Haiku\", \"id\": \"anthropic.claude-3-haiku-20240307-v1:0:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Haiku\", \"id\": \"anthropic.claude-3-haiku-20240307-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0:12k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0:28k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.5 Sonnet\", \"id\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.5 Sonnet v2\", \"id\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.7 Sonnet\", \"id\": \"anthropic.claude-3-7-sonnet-20250219-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.5 Haiku\", \"id\": \"anthropic.claude-3-5-haiku-20241022-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Command\", \"id\": \"cohere.command-text-v14:7:4k\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command\", \"id\": \"cohere.command-text-v14\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command R\", \"id\": \"cohere.command-r-v1:0\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command R+\", \"id\": \"cohere.command-r-plus-v1:0\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command Light\", \"id\": \"cohere.command-light-text-v14:7:4k\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command Light\", \"id\": \"cohere.command-light-text-v14\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed English\", \"id\": \"cohere.embed-english-v3:0:512\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed English\", \"id\": \"cohere.embed-english-v3\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed Multilingual\", \"id\": \"cohere.embed-multilingual-v3:0:512\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed Multilingual\", \"id\": \"cohere.embed-multilingual-v3\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Llama 3 8B Instruct\", \"id\": \"meta.llama3-8b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3 70B Instruct\", \"id\": \"meta.llama3-70b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.1 8B Instruct\", \"id\": \"meta.llama3-1-8b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.1 70B Instruct\", \"id\": \"meta.llama3-1-70b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 11B Instruct\", \"id\": \"meta.llama3-2-11b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 90B Instruct\", \"id\": \"meta.llama3-2-90b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 1B Instruct\", \"id\": \"meta.llama3-2-1b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 3B Instruct\", \"id\": \"meta.llama3-2-3b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.3 70B Instruct\", \"id\": \"meta.llama3-3-70b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Mistral 7B Instruct\", \"id\": \"mistral.mistral-7b-instruct-v0:2\", \"provider\": \"Mistral AI\"},\n",
    "    {\"name\": \"Mixtral 8x7B Instruct\", \"id\": \"mistral.mixtral-8x7b-instruct-v0:1\", \"provider\": \"Mistral AI\"},\n",
    "    {\"name\": \"Mistral Large (24.02)\", \"id\": \"mistral.mistral-large-2402-v1:0\", \"provider\": \"Mistral AI\"},\n",
    "    {\"name\": \"Mistral Small (24.02)\", \"id\": \"mistral.mistral-small-2402-v1:0\", \"provider\": \"Mistral AI\"}\n",
    "]\n",
    "\n",
    "# Test input\n",
    "test_input = \"I like this!\"\n",
    "prompt = f\"In only one word classify the sentiment of '{test_input}' into either Positive or Negative only. Do not use any other words for classification. Use only Positive or Negative\"\n",
    "\n",
    "def test_model(model):\n",
    "    # Customize request body based on provider\n",
    "    if \"anthropic\" in model[\"id\"]:\n",
    "        request_body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 10,  # Small output expected\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 1.0\n",
    "        }\n",
    "    elif \"amazon\" in model[\"id\"] and \"embed\" in model[\"id\"]:\n",
    "        # Embedding models expect different input\n",
    "        request_body = {\"inputText\": test_input}\n",
    "    elif \"amazon\" in model[\"id\"] and \"image\" in model[\"id\"]:\n",
    "        # Image models need image-specific input; skip for text test\n",
    "        return \"Skipped\", \"Image generation model, not applicable for text sentiment\"\n",
    "    else:\n",
    "        # Generic format for most text models (Amazon, Meta, Mistral, AI21, Cohere)\n",
    "        request_body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 10,\n",
    "            \"temperature\": 0.1\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        response = client.invoke_model(\n",
    "            modelId=model[\"id\"],\n",
    "            contentType='application/json',\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        result = json.loads(response['body'].read().decode())\n",
    "\n",
    "        # Extract output based on provider response structure\n",
    "        if \"anthropic\" in model[\"id\"]:\n",
    "            output = result['content'][0]['text'].strip()\n",
    "        elif \"amazon\" in model[\"id\"] and \"embed\" in model[\"id\"]:\n",
    "            return \"Skipped\", \"Embedding model, not applicable for sentiment\"\n",
    "        elif \"amazon\" in model[\"id\"]:\n",
    "            output = result.get('results', [{}])[0].get('outputText', 'Unknown').strip()\n",
    "        elif \"meta\" in model[\"id\"] or \"mistral\" in model[\"id\"]:\n",
    "            output = result.get('generation', result.get('text', 'Unknown')).strip()\n",
    "        elif \"ai21\" in model[\"id\"]:\n",
    "            output = result.get('completions', [{}])[0].get('data', {}).get('text', 'Unknown').strip()\n",
    "        elif \"cohere\" in model[\"id\"] and \"embed\" not in model[\"id\"]:\n",
    "            output = result.get('generations', [{}])[0].get('text', 'Unknown').strip()\n",
    "        else:\n",
    "            output = result.get('text', 'Unknown').strip()\n",
    "\n",
    "        # Validate response\n",
    "        if output in [\"Positive\", \"Negative\"]:\n",
    "            return \"Success\", output\n",
    "        else:\n",
    "            return \"Invalid\", f\"Unexpected output: {output}\"\n",
    "    except ClientError as e:\n",
    "        return \"Error\", str(e)\n",
    "    except Exception as e:\n",
    "        return \"Error\", f\"Unexpected error: {str(e)}\"\n",
    "\n",
    "# Run tests\n",
    "print(\"Testing Bedrock Models (March 5, 2025):\")\n",
    "print(\"-\" * 80)\n",
    "res=[]\n",
    "for model in models_to_test:\n",
    "    status, details = test_model(model)\n",
    "    print(f\"Model: {model['name']:<25} | ID: {model['id']:<40} | Status: {status:<10} | Details: {details}\")\n",
    "    if status == \"Success\":\n",
    "        res.append(model['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:24:15.610809Z",
     "iopub.status.busy": "2025-03-05T20:24:15.610196Z",
     "iopub.status.idle": "2025-03-05T20:24:15.614112Z",
     "shell.execute_reply": "2025-03-05T20:24:15.613586Z",
     "shell.execute_reply.started": "2025-03-05T20:24:15.610786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models working:\n",
      "['Claude 3 Sonnet', 'Claude 3.5 Sonnet']\n"
     ]
    }
   ],
   "source": [
    "print(\"Models working:\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only 2 models are working which are Claude 3 Sonnet and Claude 3.5 Sonnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select two distinct LLMs (e.g., Claude, LLaMA) for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:31:35.590538Z",
     "iopub.status.busy": "2025-03-05T20:31:35.590166Z",
     "iopub.status.idle": "2025-03-05T20:31:35.593217Z",
     "shell.execute_reply": "2025-03-05T20:31:35.592705Z",
     "shell.execute_reply.started": "2025-03-05T20:31:35.590517Z"
    }
   },
   "source": [
    "### Model 1: Claude 3 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:05:12.824304Z",
     "iopub.status.busy": "2025-03-05T21:05:12.823975Z",
     "iopub.status.idle": "2025-03-05T21:05:12.829782Z",
     "shell.execute_reply": "2025-03-05T21:05:12.829264Z",
     "shell.execute_reply.started": "2025-03-05T21:05:12.824286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_Prediction\n",
       "Positive    51\n",
       "Negative    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Claude3_Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:05:13.796291Z",
     "iopub.status.busy": "2025-03-05T21:05:13.796049Z",
     "iopub.status.idle": "2025-03-05T21:05:13.806948Z",
     "shell.execute_reply": "2025-03-05T21:05:13.806445Z",
     "shell.execute_reply.started": "2025-03-05T21:05:13.796276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.00%\n",
      "Precision: 0.96\n",
      "Recall: 0.98\n",
      "F1-Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:35:46.276087Z",
     "iopub.status.busy": "2025-03-05T20:35:46.275832Z",
     "iopub.status.idle": "2025-03-05T20:35:46.278603Z",
     "shell.execute_reply": "2025-03-05T20:35:46.278091Z",
     "shell.execute_reply.started": "2025-03-05T20:35:46.276069Z"
    }
   },
   "source": [
    "### Model 2: Claude 3.5 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:07:22.610364Z",
     "iopub.status.busy": "2025-03-05T21:07:22.610069Z",
     "iopub.status.idle": "2025-03-05T21:08:29.620861Z",
     "shell.execute_reply": "2025-03-05T21:08:29.619491Z",
     "shell.execute_reply.started": "2025-03-05T21:07:22.610345Z"
    }
   },
   "outputs": [],
   "source": [
    "Claude3_5 = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "\n",
    "df1['Claude3_5_Prediction'] = LLM(df1['text'], Claude3_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:36:03.468449Z",
     "iopub.status.busy": "2025-03-05T20:36:03.468126Z",
     "iopub.status.idle": "2025-03-05T20:36:03.474718Z",
     "shell.execute_reply": "2025-03-05T20:36:03.474207Z",
     "shell.execute_reply.started": "2025-03-05T20:36:03.468431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_5_Prediction\n",
       "Positive    50\n",
       "Negative    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Claude3_5_Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:36:26.865642Z",
     "iopub.status.busy": "2025-03-05T20:36:26.865324Z",
     "iopub.status.idle": "2025-03-05T20:36:26.876507Z",
     "shell.execute_reply": "2025-03-05T20:36:26.876017Z",
     "shell.execute_reply.started": "2025-03-05T20:36:26.865622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.00%\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_5_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:21:55.311794Z",
     "iopub.status.busy": "2025-03-05T21:21:55.311230Z",
     "iopub.status.idle": "2025-03-05T21:21:55.315414Z",
     "shell.execute_reply": "2025-03-05T21:21:55.314904Z",
     "shell.execute_reply.started": "2025-03-05T21:21:55.311775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Claude3 Predictions:\n",
      "['Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative']\n",
      "\n",
      "All Claude3.5 Predictions:\n",
      "['Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative']\n"
     ]
    }
   ],
   "source": [
    "print(\"All Claude3 Predictions:\")\n",
    "print(df1['Claude3_Prediction'].tolist())\n",
    "\n",
    "print(\"\\nAll Claude3.5 Predictions:\")\n",
    "print(df1['Claude3_5_Prediction'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T21:21:58.712237Z",
     "iopub.status.busy": "2025-03-05T21:21:58.711959Z",
     "iopub.status.idle": "2025-03-05T21:21:58.718210Z",
     "shell.execute_reply": "2025-03-05T21:21:58.717719Z",
     "shell.execute_reply.started": "2025-03-05T21:21:58.712220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Prediction Counts:\n",
      "          Claude3  Claude3.5\n",
      "Positive       51         51\n",
      "Negative       49         49\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Claude3': df1['Claude3_Prediction'].value_counts(), 'Claude3.5': df1['Claude3_5_Prediction'].value_counts()})\n",
    "print(\"\\nComparison of Prediction Counts:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cell 6 (20%) - Discussion and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and contrast the performance of zero-shot and few-shot learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude3.5 shows a marginal improvement over Claude3:\n",
    "\n",
    "* 1% higher accuracy (98% vs. 97%).\n",
    "* 0.02 better precision (0.98 vs. 0.96), reducing false positives.\n",
    "* Identical recall (0.98), with no trade-off in detecting positives.\n",
    "* 0.01 better F1-score (0.98 vs. 0.97), indicating a balanced gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
