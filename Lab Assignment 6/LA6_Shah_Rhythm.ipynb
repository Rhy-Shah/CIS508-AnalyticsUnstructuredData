{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ Rhythm Shah\n",
    "\n",
    "~ 1233960561\n",
    "\n",
    "~ 03/04/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 1 (5%) - Import Required Libraries and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary libraries for data processing, NLP, and interaction with LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:16.725544Z",
     "iopub.status.busy": "2025-03-06T00:53:16.725375Z",
     "iopub.status.idle": "2025-03-06T00:53:17.077404Z",
     "shell.execute_reply": "2025-03-06T00:53:17.076931Z",
     "shell.execute_reply.started": "2025-03-06T00:53:16.725527Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import json\n",
    "import boto3\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load restaurant_reviews_az.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.079995Z",
     "iopub.status.busy": "2025-03-06T00:53:17.079791Z",
     "iopub.status.idle": "2025-03-06T00:53:17.449300Z",
     "shell.execute_reply": "2025-03-06T00:53:17.448789Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.079978Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('restaurant_reviews_az.csv')[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.450108Z",
     "iopub.status.busy": "2025-03-06T00:53:17.449873Z",
     "iopub.status.idle": "2025-03-06T00:53:17.455067Z",
     "shell.execute_reply": "2025-03-06T00:53:17.454683Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.450091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 2 (5%) - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T08:09:15.593285Z",
     "iopub.status.busy": "2025-03-05T08:09:15.592859Z",
     "iopub.status.idle": "2025-03-05T08:09:15.596805Z",
     "shell.execute_reply": "2025-03-05T08:09:15.596083Z",
     "shell.execute_reply.started": "2025-03-05T08:09:15.593264Z"
    }
   },
   "source": [
    "## Remove 3-star reviews from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.457828Z",
     "iopub.status.busy": "2025-03-06T00:53:17.457638Z",
     "iopub.status.idle": "2025-03-06T00:53:17.465849Z",
     "shell.execute_reply": "2025-03-06T00:53:17.465435Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.457812Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['stars'] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new column Sentiment where:\n",
    "Reviews with 1 or 2 stars are labeled as 0 (Negative Sentiment).\n",
    "Reviews with 4 or 5 stars are labeled as 1 (Positive Sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.467545Z",
     "iopub.status.busy": "2025-03-06T00:53:17.467400Z",
     "iopub.status.idle": "2025-03-06T00:53:17.471226Z",
     "shell.execute_reply": "2025-03-06T00:53:17.470833Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.467531Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['stars'].apply(lambda x: 1 if x >= 4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset for this assignment by randomly selecting 50 positive reviews and 50 negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.473985Z",
     "iopub.status.busy": "2025-03-06T00:53:17.473840Z",
     "iopub.status.idle": "2025-03-06T00:53:17.485073Z",
     "shell.execute_reply": "2025-03-06T00:53:17.484649Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.473970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cARyBadkK5vj8veqnkY5Hg</td>\n",
       "      <td>P-5Wo3jjX-tn6-3jZzqqIw</td>\n",
       "      <td>Ei5HBqe012ImhqEr2ZH2gg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Delicious. Wish we lived in the area we would ...</td>\n",
       "      <td>2020-06-13 18:48:12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KTtV66u7648dDrOAHmXzvA</td>\n",
       "      <td>_o-g7aXHfLfBs3cNkvDngA</td>\n",
       "      <td>-3-6BB10tIWNKGEF0Es2BA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We were craving food from here where you reall...</td>\n",
       "      <td>2021-08-05 00:47:14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eCx23JnRfj0TRc4HCDTSKw</td>\n",
       "      <td>s6fzF2pSnUebFyVhGjh_SQ</td>\n",
       "      <td>lhsQkb5nhf-Kd5OvgB9MNg</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Been skeptical about going out to eat, but fam...</td>\n",
       "      <td>2020-06-30 03:40:12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2AtefJfe983yRvXfHxGhg</td>\n",
       "      <td>meQCVrrJxwdjS_1BFooTUg</td>\n",
       "      <td>gMpYdAe1lZWDuBRw2bPEhg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My first time trying their food. Absolutely de...</td>\n",
       "      <td>2021-04-20 01:53:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rLf-518KWHtM0bh8jEkQeQ</td>\n",
       "      <td>pgUQjUl_2G5L9EreDzIjSw</td>\n",
       "      <td>UCMSWPqzXjd7QHq7v8PJjQ</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>This place has been on my list to try since my...</td>\n",
       "      <td>2020-03-19 21:16:35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  cARyBadkK5vj8veqnkY5Hg  P-5Wo3jjX-tn6-3jZzqqIw  Ei5HBqe012ImhqEr2ZH2gg   \n",
       "1  KTtV66u7648dDrOAHmXzvA  _o-g7aXHfLfBs3cNkvDngA  -3-6BB10tIWNKGEF0Es2BA   \n",
       "2  eCx23JnRfj0TRc4HCDTSKw  s6fzF2pSnUebFyVhGjh_SQ  lhsQkb5nhf-Kd5OvgB9MNg   \n",
       "3  W2AtefJfe983yRvXfHxGhg  meQCVrrJxwdjS_1BFooTUg  gMpYdAe1lZWDuBRw2bPEhg   \n",
       "4  rLf-518KWHtM0bh8jEkQeQ  pgUQjUl_2G5L9EreDzIjSw  UCMSWPqzXjd7QHq7v8PJjQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       0      0     0   \n",
       "1      5       0      0     0   \n",
       "2      5       1      0     0   \n",
       "3      5       0      0     0   \n",
       "4      4       6      2     5   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Delicious. Wish we lived in the area we would ...  2020-06-13 18:48:12   \n",
       "1  We were craving food from here where you reall...  2021-08-05 00:47:14   \n",
       "2  Been skeptical about going out to eat, but fam...  2020-06-30 03:40:12   \n",
       "3  My first time trying their food. Absolutely de...  2021-04-20 01:53:18   \n",
       "4  This place has been on my list to try since my...  2020-03-19 21:16:35   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews = df[df['Sentiment'] == 1].sample(n=50)\n",
    "negative_reviews = df[df['Sentiment'] == 0].sample(n=50)\n",
    "\n",
    "df1 = pd.concat([positive_reviews, negative_reviews]).reset_index(drop=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.485815Z",
     "iopub.status.busy": "2025-03-06T00:53:17.485590Z",
     "iopub.status.idle": "2025-03-06T00:53:17.488707Z",
     "shell.execute_reply": "2025-03-06T00:53:17.488289Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.485800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 3 (20%) - Perform Sentiment Analysis Using Zero-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T08:11:09.610991Z",
     "iopub.status.busy": "2025-03-05T08:11:09.610516Z",
     "iopub.status.idle": "2025-03-05T08:11:09.614330Z",
     "shell.execute_reply": "2025-03-05T08:11:09.613741Z",
     "shell.execute_reply.started": "2025-03-05T08:11:09.610966Z"
    }
   },
   "source": [
    "## Use a Claude 3 Sonnet for zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.491622Z",
     "iopub.status.busy": "2025-03-06T00:53:17.491286Z",
     "iopub.status.idle": "2025-03-06T00:53:17.539357Z",
     "shell.execute_reply": "2025-03-06T00:53:17.538943Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.491605Z"
    }
   },
   "outputs": [],
   "source": [
    "client = boto3.client(\"bedrock-runtime\", region_name = \"us-east-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict sentiment labels for the selected 100 reviews without providing any labeled training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.541119Z",
     "iopub.status.busy": "2025-03-06T00:53:17.540967Z",
     "iopub.status.idle": "2025-03-06T00:53:17.545039Z",
     "shell.execute_reply": "2025-03-06T00:53:17.544632Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.541103Z"
    }
   },
   "outputs": [],
   "source": [
    "def LLM(data, model_id):\n",
    "    results = []\n",
    "\n",
    "    for i in data:\n",
    "        messages = [{\"role\": \"user\", \"content\": f\"In only one word classify the sentiment of '{i}' into either Positive or Negative only. Do not use any other words such as neutral for classification. Use only Positive or Negative\"}]\n",
    "\n",
    "        request_body = {\"anthropic_version\": \"bedrock-2023-05-31\", \"messages\": messages, \"max_tokens\": 512, \"temperature\": 0.2, \"top_p\": 1.0}\n",
    "\n",
    "        try:\n",
    "            response = client.invoke_model(modelId = model_id, contentType = 'application/json', body = json.dumps(request_body))\n",
    "            result = json.loads(response['body'].read().decode())\n",
    "            sentiment = result['content'][0]['text'].strip()\n",
    "            results.append(sentiment)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text '{i}': {e}\")\n",
    "            results.append(\"Error\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a general code which is flexible to different models. I just need to pass the model id in the function parameter along with the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:53:17.546652Z",
     "iopub.status.busy": "2025-03-06T00:53:17.546504Z",
     "iopub.status.idle": "2025-03-06T00:54:02.225221Z",
     "shell.execute_reply": "2025-03-06T00:54:02.224620Z",
     "shell.execute_reply.started": "2025-03-06T00:53:17.546638Z"
    }
   },
   "outputs": [],
   "source": [
    "Claude3 = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "df1['Claude3_Prediction'] = LLM(df1['text'], Claude3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:02.226206Z",
     "iopub.status.busy": "2025-03-06T00:54:02.225938Z",
     "iopub.status.idle": "2025-03-06T00:54:02.234775Z",
     "shell.execute_reply": "2025-03-06T00:54:02.234277Z",
     "shell.execute_reply.started": "2025-03-06T00:54:02.226188Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Claude3_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cARyBadkK5vj8veqnkY5Hg</td>\n",
       "      <td>P-5Wo3jjX-tn6-3jZzqqIw</td>\n",
       "      <td>Ei5HBqe012ImhqEr2ZH2gg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Delicious. Wish we lived in the area we would ...</td>\n",
       "      <td>2020-06-13 18:48:12</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KTtV66u7648dDrOAHmXzvA</td>\n",
       "      <td>_o-g7aXHfLfBs3cNkvDngA</td>\n",
       "      <td>-3-6BB10tIWNKGEF0Es2BA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We were craving food from here where you reall...</td>\n",
       "      <td>2021-08-05 00:47:14</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eCx23JnRfj0TRc4HCDTSKw</td>\n",
       "      <td>s6fzF2pSnUebFyVhGjh_SQ</td>\n",
       "      <td>lhsQkb5nhf-Kd5OvgB9MNg</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Been skeptical about going out to eat, but fam...</td>\n",
       "      <td>2020-06-30 03:40:12</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2AtefJfe983yRvXfHxGhg</td>\n",
       "      <td>meQCVrrJxwdjS_1BFooTUg</td>\n",
       "      <td>gMpYdAe1lZWDuBRw2bPEhg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My first time trying their food. Absolutely de...</td>\n",
       "      <td>2021-04-20 01:53:18</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rLf-518KWHtM0bh8jEkQeQ</td>\n",
       "      <td>pgUQjUl_2G5L9EreDzIjSw</td>\n",
       "      <td>UCMSWPqzXjd7QHq7v8PJjQ</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>This place has been on my list to try since my...</td>\n",
       "      <td>2020-03-19 21:16:35</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  cARyBadkK5vj8veqnkY5Hg  P-5Wo3jjX-tn6-3jZzqqIw  Ei5HBqe012ImhqEr2ZH2gg   \n",
       "1  KTtV66u7648dDrOAHmXzvA  _o-g7aXHfLfBs3cNkvDngA  -3-6BB10tIWNKGEF0Es2BA   \n",
       "2  eCx23JnRfj0TRc4HCDTSKw  s6fzF2pSnUebFyVhGjh_SQ  lhsQkb5nhf-Kd5OvgB9MNg   \n",
       "3  W2AtefJfe983yRvXfHxGhg  meQCVrrJxwdjS_1BFooTUg  gMpYdAe1lZWDuBRw2bPEhg   \n",
       "4  rLf-518KWHtM0bh8jEkQeQ  pgUQjUl_2G5L9EreDzIjSw  UCMSWPqzXjd7QHq7v8PJjQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       0      0     0   \n",
       "1      5       0      0     0   \n",
       "2      5       1      0     0   \n",
       "3      5       0      0     0   \n",
       "4      4       6      2     5   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Delicious. Wish we lived in the area we would ...  2020-06-13 18:48:12   \n",
       "1  We were craving food from here where you reall...  2021-08-05 00:47:14   \n",
       "2  Been skeptical about going out to eat, but fam...  2020-06-30 03:40:12   \n",
       "3  My first time trying their food. Absolutely de...  2021-04-20 01:53:18   \n",
       "4  This place has been on my list to try since my...  2020-03-19 21:16:35   \n",
       "\n",
       "   Sentiment Claude3_Prediction  \n",
       "0          1           Positive  \n",
       "1          1           Positive  \n",
       "2          1           Positive  \n",
       "3          1           Positive  \n",
       "4          1           Positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:02.235578Z",
     "iopub.status.busy": "2025-03-06T00:54:02.235348Z",
     "iopub.status.idle": "2025-03-06T00:54:02.242627Z",
     "shell.execute_reply": "2025-03-06T00:54:02.242174Z",
     "shell.execute_reply.started": "2025-03-06T00:54:02.235561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_Prediction\n",
       "Negative    51\n",
       "Positive    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Claude3_Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance using precision, recall, f1, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:02.244579Z",
     "iopub.status.busy": "2025-03-06T00:54:02.244411Z",
     "iopub.status.idle": "2025-03-06T00:54:02.248653Z",
     "shell.execute_reply": "2025-03-06T00:54:02.248183Z",
     "shell.execute_reply.started": "2025-03-06T00:54:02.244549Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model_performance(pred_col, true_col = \"Sentiment\"):\n",
    "    y_true = df1[true_col]\n",
    "    y_pred = df1[pred_col].map({\"Positive\": 1, \"Negative\": 0})\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a general code for calculate the model metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:02.252634Z",
     "iopub.status.busy": "2025-03-06T00:54:02.252300Z",
     "iopub.status.idle": "2025-03-06T00:54:02.262991Z",
     "shell.execute_reply": "2025-03-06T00:54:02.262528Z",
     "shell.execute_reply.started": "2025-03-06T00:54:02.252596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.00%\n",
      "Precision: 0.98\n",
      "Recall: 0.96\n",
      "F1-Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 4 (20%) - Perform Sentiment Analysis Using Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a few examples for few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:02.266094Z",
     "iopub.status.busy": "2025-03-06T00:54:02.265942Z",
     "iopub.status.idle": "2025-03-06T00:54:02.268745Z",
     "shell.execute_reply": "2025-03-06T00:54:02.268273Z",
     "shell.execute_reply.started": "2025-03-06T00:54:02.266080Z"
    }
   },
   "outputs": [],
   "source": [
    "few_shot_prefix = \"\"\"\n",
    "Examples:\n",
    "1. \"Amazing food, great service!\" -> Positive\n",
    "2. \"Terrible experience, rude staff.\" -> Negative\n",
    "3. \"It was okay, nothing special.\" -> Positive\n",
    "4. \"Slow delivery, cold meal.\" -> Negative\n",
    "5. \"The atmosphere was cozy and inviting.\" -> Positive\n",
    "6. \"Overpriced and underwhelming quality.\" -> Negative\n",
    "7. \"Friendly team, quick response time.\" -> Positive\n",
    "8. \"Broken product, no refund offered.\" -> Negative\n",
    "9. \"Exceeded my expectations, highly recommend!\" -> Positive\n",
    "10. \"Disappointing, wouldnâ€™t come back.\" -> Negative\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T09:04:07.008518Z",
     "iopub.status.busy": "2025-03-05T09:04:07.008043Z",
     "iopub.status.idle": "2025-03-05T09:04:07.011505Z",
     "shell.execute_reply": "2025-03-05T09:04:07.010978Z",
     "shell.execute_reply.started": "2025-03-05T09:04:07.008495Z"
    }
   },
   "source": [
    "## Use the example(s) to guide the LLM in classifying sentiment for the selected 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:02.270602Z",
     "iopub.status.busy": "2025-03-06T00:54:02.270447Z",
     "iopub.status.idle": "2025-03-06T00:54:49.726543Z",
     "shell.execute_reply": "2025-03-06T00:54:49.725820Z",
     "shell.execute_reply.started": "2025-03-06T00:54:02.270588Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['Claude3_FewShot_Prediction'] = LLM(few_shot_prefix + df1['text'], Claude3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:49.727489Z",
     "iopub.status.busy": "2025-03-06T00:54:49.727228Z",
     "iopub.status.idle": "2025-03-06T00:54:49.732403Z",
     "shell.execute_reply": "2025-03-06T00:54:49.731963Z",
     "shell.execute_reply.started": "2025-03-06T00:54:49.727471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_FewShot_Prediction\n",
       "Negative    51\n",
       "Positive    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Claude3_FewShot_Prediction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance using precision, recall, f1, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:49.734616Z",
     "iopub.status.busy": "2025-03-06T00:54:49.734395Z",
     "iopub.status.idle": "2025-03-06T00:54:49.744974Z",
     "shell.execute_reply": "2025-03-06T00:54:49.744448Z",
     "shell.execute_reply.started": "2025-03-06T00:54:49.734599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.00%\n",
      "Precision: 1.00\n",
      "Recall: 0.98\n",
      "F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_FewShot_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cell 5 (20%) - Experiment with Multiple LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checking for working models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:49.748242Z",
     "iopub.status.busy": "2025-03-06T00:54:49.748088Z",
     "iopub.status.idle": "2025-03-06T00:54:49.833400Z",
     "shell.execute_reply": "2025-03-06T00:54:49.832928Z",
     "shell.execute_reply.started": "2025-03-06T00:54:49.748227Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Titan Text Large, Model ID: amazon.titan-tg1-large, Provider: Amazon\n",
      "Model Name: Titan Image Generator G1, Model ID: amazon.titan-image-generator-v1:0, Provider: Amazon\n",
      "Model Name: Titan Image Generator G1, Model ID: amazon.titan-image-generator-v1, Provider: Amazon\n",
      "Model Name: Titan Image Generator G1 v2, Model ID: amazon.titan-image-generator-v2:0, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Premier, Model ID: amazon.titan-text-premier-v1:0, Provider: Amazon\n",
      "Model Name: Nova Pro, Model ID: amazon.nova-pro-v1:0:300k, Provider: Amazon\n",
      "Model Name: Nova Pro, Model ID: amazon.nova-pro-v1:0, Provider: Amazon\n",
      "Model Name: Nova Lite, Model ID: amazon.nova-lite-v1:0:300k, Provider: Amazon\n",
      "Model Name: Nova Lite, Model ID: amazon.nova-lite-v1:0, Provider: Amazon\n",
      "Model Name: Nova Canvas, Model ID: amazon.nova-canvas-v1:0, Provider: Amazon\n",
      "Model Name: Nova Reel, Model ID: amazon.nova-reel-v1:0, Provider: Amazon\n",
      "Model Name: Nova Micro, Model ID: amazon.nova-micro-v1:0:128k, Provider: Amazon\n",
      "Model Name: Nova Micro, Model ID: amazon.nova-micro-v1:0, Provider: Amazon\n",
      "Model Name: Titan Text Embeddings v2, Model ID: amazon.titan-embed-g1-text-02, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Lite, Model ID: amazon.titan-text-lite-v1:0:4k, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Lite, Model ID: amazon.titan-text-lite-v1, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Express, Model ID: amazon.titan-text-express-v1:0:8k, Provider: Amazon\n",
      "Model Name: Titan Text G1 - Express, Model ID: amazon.titan-text-express-v1, Provider: Amazon\n",
      "Model Name: Titan Embeddings G1 - Text, Model ID: amazon.titan-embed-text-v1:2:8k, Provider: Amazon\n",
      "Model Name: Titan Embeddings G1 - Text, Model ID: amazon.titan-embed-text-v1, Provider: Amazon\n",
      "Model Name: Titan Text Embeddings V2, Model ID: amazon.titan-embed-text-v2:0:8k, Provider: Amazon\n",
      "Model Name: Titan Text Embeddings V2, Model ID: amazon.titan-embed-text-v2:0, Provider: Amazon\n",
      "Model Name: Titan Multimodal Embeddings G1, Model ID: amazon.titan-embed-image-v1:0, Provider: Amazon\n",
      "Model Name: Titan Multimodal Embeddings G1, Model ID: amazon.titan-embed-image-v1, Provider: Amazon\n",
      "Model Name: SDXL 1.0, Model ID: stability.stable-diffusion-xl-v1:0, Provider: Stability AI\n",
      "Model Name: SDXL 1.0, Model ID: stability.stable-diffusion-xl-v1, Provider: Stability AI\n",
      "Model Name: J2 Grande Instruct, Model ID: ai21.j2-grande-instruct, Provider: AI21 Labs\n",
      "Model Name: J2 Jumbo Instruct, Model ID: ai21.j2-jumbo-instruct, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Mid, Model ID: ai21.j2-mid, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Mid, Model ID: ai21.j2-mid-v1, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Ultra, Model ID: ai21.j2-ultra, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Ultra, Model ID: ai21.j2-ultra-v1:0:8k, Provider: AI21 Labs\n",
      "Model Name: Jurassic-2 Ultra, Model ID: ai21.j2-ultra-v1, Provider: AI21 Labs\n",
      "Model Name: Jamba-Instruct, Model ID: ai21.jamba-instruct-v1:0, Provider: AI21 Labs\n",
      "Model Name: Jamba 1.5 Large, Model ID: ai21.jamba-1-5-large-v1:0, Provider: AI21 Labs\n",
      "Model Name: Jamba 1.5 Mini, Model ID: ai21.jamba-1-5-mini-v1:0, Provider: AI21 Labs\n",
      "Model Name: Claude Instant, Model ID: anthropic.claude-instant-v1:2:100k, Provider: Anthropic\n",
      "Model Name: Claude Instant, Model ID: anthropic.claude-instant-v1, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:0:18k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:0:100k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:1:18k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:1:200k, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2:1, Provider: Anthropic\n",
      "Model Name: Claude, Model ID: anthropic.claude-v2, Provider: Anthropic\n",
      "Model Name: Claude 3 Sonnet, Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k, Provider: Anthropic\n",
      "Model Name: Claude 3 Sonnet, Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k, Provider: Anthropic\n",
      "Model Name: Claude 3 Sonnet, Model ID: anthropic.claude-3-sonnet-20240229-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3 Haiku, Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k, Provider: Anthropic\n",
      "Model Name: Claude 3 Haiku, Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k, Provider: Anthropic\n",
      "Model Name: Claude 3 Haiku, Model ID: anthropic.claude-3-haiku-20240307-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0:12k, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0:28k, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0:200k, Provider: Anthropic\n",
      "Model Name: Claude 3 Opus, Model ID: anthropic.claude-3-opus-20240229-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3.5 Sonnet, Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3.5 Sonnet v2, Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0, Provider: Anthropic\n",
      "Model Name: Claude 3.7 Sonnet, Model ID: anthropic.claude-3-7-sonnet-20250219-v1:0, Provider: Anthropic\n",
      "Model Name: Claude 3.5 Haiku, Model ID: anthropic.claude-3-5-haiku-20241022-v1:0, Provider: Anthropic\n",
      "Model Name: Command, Model ID: cohere.command-text-v14:7:4k, Provider: Cohere\n",
      "Model Name: Command, Model ID: cohere.command-text-v14, Provider: Cohere\n",
      "Model Name: Command R, Model ID: cohere.command-r-v1:0, Provider: Cohere\n",
      "Model Name: Command R+, Model ID: cohere.command-r-plus-v1:0, Provider: Cohere\n",
      "Model Name: Command Light, Model ID: cohere.command-light-text-v14:7:4k, Provider: Cohere\n",
      "Model Name: Command Light, Model ID: cohere.command-light-text-v14, Provider: Cohere\n",
      "Model Name: Embed English, Model ID: cohere.embed-english-v3:0:512, Provider: Cohere\n",
      "Model Name: Embed English, Model ID: cohere.embed-english-v3, Provider: Cohere\n",
      "Model Name: Embed Multilingual, Model ID: cohere.embed-multilingual-v3:0:512, Provider: Cohere\n",
      "Model Name: Embed Multilingual, Model ID: cohere.embed-multilingual-v3, Provider: Cohere\n",
      "Model Name: Llama 3 8B Instruct, Model ID: meta.llama3-8b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3 70B Instruct, Model ID: meta.llama3-70b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.1 8B Instruct, Model ID: meta.llama3-1-8b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.1 70B Instruct, Model ID: meta.llama3-1-70b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 11B Instruct, Model ID: meta.llama3-2-11b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 90B Instruct, Model ID: meta.llama3-2-90b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 1B Instruct, Model ID: meta.llama3-2-1b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.2 3B Instruct, Model ID: meta.llama3-2-3b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Llama 3.3 70B Instruct, Model ID: meta.llama3-3-70b-instruct-v1:0, Provider: Meta\n",
      "Model Name: Mistral 7B Instruct, Model ID: mistral.mistral-7b-instruct-v0:2, Provider: Mistral AI\n",
      "Model Name: Mixtral 8x7B Instruct, Model ID: mistral.mixtral-8x7b-instruct-v0:1, Provider: Mistral AI\n",
      "Model Name: Mistral Large (24.02), Model ID: mistral.mistral-large-2402-v1:0, Provider: Mistral AI\n",
      "Model Name: Mistral Small (24.02), Model ID: mistral.mistral-small-2402-v1:0, Provider: Mistral AI\n"
     ]
    }
   ],
   "source": [
    "bedrock = boto3.client('bedrock', region_name='us-east-1')\n",
    "response = bedrock.list_foundation_models()\n",
    "\n",
    "for model in response['modelSummaries']:\n",
    "    print(f\"Model Name: {model['modelName']}, Model ID: {model['modelId']}, Provider: {model['providerName']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:49.834281Z",
     "iopub.status.busy": "2025-03-06T00:54:49.834047Z",
     "iopub.status.idle": "2025-03-06T00:54:53.698151Z",
     "shell.execute_reply": "2025-03-06T00:54:53.697436Z",
     "shell.execute_reply.started": "2025-03-06T00:54:49.834265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Bedrock Models (March 5, 2025):\n",
      "--------------------------------------------------------------------------------\n",
      "Model: Titan Text Large          | ID: amazon.titan-tg1-large                   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Image Generator G1  | ID: amazon.titan-image-generator-v1:0        | Status: Skipped    | Details: Image generation model, not applicable for text sentiment\n",
      "Model: Titan Image Generator G1  | ID: amazon.titan-image-generator-v1          | Status: Skipped    | Details: Image generation model, not applicable for text sentiment\n",
      "Model: Titan Image Generator G1 v2 | ID: amazon.titan-image-generator-v2:0        | Status: Skipped    | Details: Image generation model, not applicable for text sentiment\n",
      "Model: Titan Text G1 - Premier   | ID: amazon.titan-text-premier-v1:0           | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Pro                  | ID: amazon.nova-pro-v1:0:300k                | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Nova Pro                  | ID: amazon.nova-pro-v1:0                     | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Lite                 | ID: amazon.nova-lite-v1:0:300k               | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Nova Lite                 | ID: amazon.nova-lite-v1:0                    | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Canvas               | ID: amazon.nova-canvas-v1:0                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Nova Reel                 | ID: amazon.nova-reel-v1:0                    | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: This action doesn't support the model that you provided. Try again with a supported text or chat model.\n",
      "Model: Nova Micro                | ID: amazon.nova-micro-v1:0:128k              | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Nova Micro                | ID: amazon.nova-micro-v1:0                   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text Embeddings v2  | ID: amazon.titan-embed-g1-text-02            | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text G1 - Lite      | ID: amazon.titan-text-lite-v1:0:4k           | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Text G1 - Lite      | ID: amazon.titan-text-lite-v1                | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text G1 - Express   | ID: amazon.titan-text-express-v1:0:8k        | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Text G1 - Express   | ID: amazon.titan-text-express-v1             | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Embeddings G1 - Text | ID: amazon.titan-embed-text-v1:2:8k          | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Embeddings G1 - Text | ID: amazon.titan-embed-text-v1               | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Titan Text Embeddings V2  | ID: amazon.titan-embed-text-v2:0:8k          | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Titan Text Embeddings V2  | ID: amazon.titan-embed-text-v2:0             | Status: Skipped    | Details: Embedding model, not applicable for sentiment\n",
      "Model: Titan Multimodal Embeddings G1 | ID: amazon.titan-embed-image-v1:0            | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model doesn't support on-demand throughput.\n",
      "Model: Titan Multimodal Embeddings G1 | ID: amazon.titan-embed-image-v1              | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: SDXL 1.0                  | ID: stability.stable-diffusion-xl-v1:0       | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model doesn't support on-demand throughput.\n",
      "Model: SDXL 1.0                  | ID: stability.stable-diffusion-xl-v1         | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: J2 Grande Instruct        | ID: ai21.j2-grande-instruct                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: J2 Jumbo Instruct         | ID: ai21.j2-jumbo-instruct                   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Mid            | ID: ai21.j2-mid                              | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Mid            | ID: ai21.j2-mid-v1                           | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Ultra          | ID: ai21.j2-ultra                            | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jurassic-2 Ultra          | ID: ai21.j2-ultra-v1:0:8k                    | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Jurassic-2 Ultra          | ID: ai21.j2-ultra-v1                         | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jamba-Instruct            | ID: ai21.jamba-instruct-v1:0                 | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jamba 1.5 Large           | ID: ai21.jamba-1-5-large-v1:0                | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Jamba 1.5 Mini            | ID: ai21.jamba-1-5-mini-v1:0                 | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude Instant            | ID: anthropic.claude-instant-v1:2:100k       | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude Instant            | ID: anthropic.claude-instant-v1              | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:0:18k                | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:0:100k               | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:1:18k                | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:1:200k               | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude                    | ID: anthropic.claude-v2:1                    | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude                    | ID: anthropic.claude-v2                      | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude 3 Sonnet           | ID: anthropic.claude-3-sonnet-20240229-v1:0:28k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Sonnet           | ID: anthropic.claude-3-sonnet-20240229-v1:0:200k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Sonnet           | ID: anthropic.claude-3-sonnet-20240229-v1:0  | Status: Success    | Details: Positive\n",
      "Model: Claude 3 Haiku            | ID: anthropic.claude-3-haiku-20240307-v1:0:48k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Haiku            | ID: anthropic.claude-3-haiku-20240307-v1:0:200k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Haiku            | ID: anthropic.claude-3-haiku-20240307-v1:0   | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0:12k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0:28k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0:200k | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Claude 3 Opus             | ID: anthropic.claude-3-opus-20240229-v1:0    | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-opus-20240229-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Claude 3.5 Sonnet         | ID: anthropic.claude-3-5-sonnet-20240620-v1:0 | Status: Success    | Details: Positive\n",
      "Model: Claude 3.5 Sonnet v2      | ID: anthropic.claude-3-5-sonnet-20241022-v2:0 | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-5-sonnet-20241022-v2:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Claude 3.7 Sonnet         | ID: anthropic.claude-3-7-sonnet-20250219-v1:0 | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-7-sonnet-20250219-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Claude 3.5 Haiku          | ID: anthropic.claude-3-5-haiku-20241022-v1:0 | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID anthropic.claude-3-5-haiku-20241022-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Command                   | ID: cohere.command-text-v14:7:4k             | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Command                   | ID: cohere.command-text-v14                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Command R                 | ID: cohere.command-r-v1:0                    | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Command R+                | ID: cohere.command-r-plus-v1:0               | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Command Light             | ID: cohere.command-light-text-v14:7:4k       | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Command Light             | ID: cohere.command-light-text-v14            | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Embed English             | ID: cohere.embed-english-v3:0:512            | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Embed English             | ID: cohere.embed-english-v3                  | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Embed Multilingual        | ID: cohere.embed-multilingual-v3:0:512       | Status: Error      | Details: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: Model not found.\n",
      "Model: Embed Multilingual        | ID: cohere.embed-multilingual-v3             | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Llama 3 8B Instruct       | ID: meta.llama3-8b-instruct-v1:0             | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Llama 3 70B Instruct      | ID: meta.llama3-70b-instruct-v1:0            | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: #: extraneous key [max_tokens] is not permitted, please reformat your input and try again.\n",
      "Model: Llama 3.1 8B Instruct     | ID: meta.llama3-1-8b-instruct-v1:0           | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-1-8b-instruct-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.1 70B Instruct    | ID: meta.llama3-1-70b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-1-70b-instruct-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 11B Instruct    | ID: meta.llama3-2-11b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-11b-instruct-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 90B Instruct    | ID: meta.llama3-2-90b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-90b-instruct-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 1B Instruct     | ID: meta.llama3-2-1b-instruct-v1:0           | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-1b-instruct-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.2 3B Instruct     | ID: meta.llama3-2-3b-instruct-v1:0           | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-2-3b-instruct-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Llama 3.3 70B Instruct    | ID: meta.llama3-3-70b-instruct-v1:0          | Status: Error      | Details: An error occurred (ValidationException) when calling the InvokeModel operation: Invocation of model ID meta.llama3-3-70b-instruct-v1:0 with on-demand throughput isnâ€™t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\n",
      "Model: Mistral 7B Instruct       | ID: mistral.mistral-7b-instruct-v0:2         | Status: Invalid    | Details: Unexpected output: Unknown\n",
      "Model: Mixtral 8x7B Instruct     | ID: mistral.mixtral-8x7b-instruct-v0:1       | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Mistral Large (24.02)     | ID: mistral.mistral-large-2402-v1:0          | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n",
      "Model: Mistral Small (24.02)     | ID: mistral.mistral-small-2402-v1:0          | Status: Error      | Details: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bedrock client\n",
    "client = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "# Full list of models from your input\n",
    "models_to_test = [\n",
    "    {\"name\": \"Titan Text Large\", \"id\": \"amazon.titan-tg1-large\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Image Generator G1\", \"id\": \"amazon.titan-image-generator-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Image Generator G1\", \"id\": \"amazon.titan-image-generator-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Image Generator G1 v2\", \"id\": \"amazon.titan-image-generator-v2:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Premier\", \"id\": \"amazon.titan-text-premier-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Pro\", \"id\": \"amazon.nova-pro-v1:0:300k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Pro\", \"id\": \"amazon.nova-pro-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Lite\", \"id\": \"amazon.nova-lite-v1:0:300k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Lite\", \"id\": \"amazon.nova-lite-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Canvas\", \"id\": \"amazon.nova-canvas-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Reel\", \"id\": \"amazon.nova-reel-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Micro\", \"id\": \"amazon.nova-micro-v1:0:128k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Nova Micro\", \"id\": \"amazon.nova-micro-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text Embeddings v2\", \"id\": \"amazon.titan-embed-g1-text-02\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Lite\", \"id\": \"amazon.titan-text-lite-v1:0:4k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Lite\", \"id\": \"amazon.titan-text-lite-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Express\", \"id\": \"amazon.titan-text-express-v1:0:8k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text G1 - Express\", \"id\": \"amazon.titan-text-express-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Embeddings G1 - Text\", \"id\": \"amazon.titan-embed-text-v1:2:8k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Embeddings G1 - Text\", \"id\": \"amazon.titan-embed-text-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text Embeddings V2\", \"id\": \"amazon.titan-embed-text-v2:0:8k\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Text Embeddings V2\", \"id\": \"amazon.titan-embed-text-v2:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Multimodal Embeddings G1\", \"id\": \"amazon.titan-embed-image-v1:0\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"Titan Multimodal Embeddings G1\", \"id\": \"amazon.titan-embed-image-v1\", \"provider\": \"Amazon\"},\n",
    "    {\"name\": \"SDXL 1.0\", \"id\": \"stability.stable-diffusion-xl-v1:0\", \"provider\": \"Stability AI\"},\n",
    "    {\"name\": \"SDXL 1.0\", \"id\": \"stability.stable-diffusion-xl-v1\", \"provider\": \"Stability AI\"},\n",
    "    {\"name\": \"J2 Grande Instruct\", \"id\": \"ai21.j2-grande-instruct\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"J2 Jumbo Instruct\", \"id\": \"ai21.j2-jumbo-instruct\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Mid\", \"id\": \"ai21.j2-mid\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Mid\", \"id\": \"ai21.j2-mid-v1\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Ultra\", \"id\": \"ai21.j2-ultra\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Ultra\", \"id\": \"ai21.j2-ultra-v1:0:8k\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jurassic-2 Ultra\", \"id\": \"ai21.j2-ultra-v1\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jamba-Instruct\", \"id\": \"ai21.jamba-instruct-v1:0\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jamba 1.5 Large\", \"id\": \"ai21.jamba-1-5-large-v1:0\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Jamba 1.5 Mini\", \"id\": \"ai21.jamba-1-5-mini-v1:0\", \"provider\": \"AI21 Labs\"},\n",
    "    {\"name\": \"Claude Instant\", \"id\": \"anthropic.claude-instant-v1:2:100k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude Instant\", \"id\": \"anthropic.claude-instant-v1\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:0:18k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:0:100k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:1:18k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:1:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2:1\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude\", \"id\": \"anthropic.claude-v2\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Sonnet\", \"id\": \"anthropic.claude-3-sonnet-20240229-v1:0:28k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Sonnet\", \"id\": \"anthropic.claude-3-sonnet-20240229-v1:0:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Sonnet\", \"id\": \"anthropic.claude-3-sonnet-20240229-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Haiku\", \"id\": \"anthropic.claude-3-haiku-20240307-v1:0:48k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Haiku\", \"id\": \"anthropic.claude-3-haiku-20240307-v1:0:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Haiku\", \"id\": \"anthropic.claude-3-haiku-20240307-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0:12k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0:28k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0:200k\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3 Opus\", \"id\": \"anthropic.claude-3-opus-20240229-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.5 Sonnet\", \"id\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.5 Sonnet v2\", \"id\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.7 Sonnet\", \"id\": \"anthropic.claude-3-7-sonnet-20250219-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Claude 3.5 Haiku\", \"id\": \"anthropic.claude-3-5-haiku-20241022-v1:0\", \"provider\": \"Anthropic\"},\n",
    "    {\"name\": \"Command\", \"id\": \"cohere.command-text-v14:7:4k\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command\", \"id\": \"cohere.command-text-v14\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command R\", \"id\": \"cohere.command-r-v1:0\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command R+\", \"id\": \"cohere.command-r-plus-v1:0\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command Light\", \"id\": \"cohere.command-light-text-v14:7:4k\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Command Light\", \"id\": \"cohere.command-light-text-v14\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed English\", \"id\": \"cohere.embed-english-v3:0:512\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed English\", \"id\": \"cohere.embed-english-v3\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed Multilingual\", \"id\": \"cohere.embed-multilingual-v3:0:512\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Embed Multilingual\", \"id\": \"cohere.embed-multilingual-v3\", \"provider\": \"Cohere\"},\n",
    "    {\"name\": \"Llama 3 8B Instruct\", \"id\": \"meta.llama3-8b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3 70B Instruct\", \"id\": \"meta.llama3-70b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.1 8B Instruct\", \"id\": \"meta.llama3-1-8b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.1 70B Instruct\", \"id\": \"meta.llama3-1-70b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 11B Instruct\", \"id\": \"meta.llama3-2-11b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 90B Instruct\", \"id\": \"meta.llama3-2-90b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 1B Instruct\", \"id\": \"meta.llama3-2-1b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.2 3B Instruct\", \"id\": \"meta.llama3-2-3b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Llama 3.3 70B Instruct\", \"id\": \"meta.llama3-3-70b-instruct-v1:0\", \"provider\": \"Meta\"},\n",
    "    {\"name\": \"Mistral 7B Instruct\", \"id\": \"mistral.mistral-7b-instruct-v0:2\", \"provider\": \"Mistral AI\"},\n",
    "    {\"name\": \"Mixtral 8x7B Instruct\", \"id\": \"mistral.mixtral-8x7b-instruct-v0:1\", \"provider\": \"Mistral AI\"},\n",
    "    {\"name\": \"Mistral Large (24.02)\", \"id\": \"mistral.mistral-large-2402-v1:0\", \"provider\": \"Mistral AI\"},\n",
    "    {\"name\": \"Mistral Small (24.02)\", \"id\": \"mistral.mistral-small-2402-v1:0\", \"provider\": \"Mistral AI\"}\n",
    "]\n",
    "\n",
    "# Test input\n",
    "test_input = \"I like this!\"\n",
    "prompt = f\"In only one word classify the sentiment of '{test_input}' into either Positive or Negative only. Do not use any other words for classification. Use only Positive or Negative\"\n",
    "\n",
    "def test_model(model):\n",
    "    # Customize request body based on provider\n",
    "    if \"anthropic\" in model[\"id\"]:\n",
    "        request_body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 10,  # Small output expected\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 1.0\n",
    "        }\n",
    "    elif \"amazon\" in model[\"id\"] and \"embed\" in model[\"id\"]:\n",
    "        # Embedding models expect different input\n",
    "        request_body = {\"inputText\": test_input}\n",
    "    elif \"amazon\" in model[\"id\"] and \"image\" in model[\"id\"]:\n",
    "        # Image models need image-specific input; skip for text test\n",
    "        return \"Skipped\", \"Image generation model, not applicable for text sentiment\"\n",
    "    else:\n",
    "        # Generic format for most text models (Amazon, Meta, Mistral, AI21, Cohere)\n",
    "        request_body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 10,\n",
    "            \"temperature\": 0.1\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        response = client.invoke_model(\n",
    "            modelId=model[\"id\"],\n",
    "            contentType='application/json',\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        result = json.loads(response['body'].read().decode())\n",
    "\n",
    "        # Extract output based on provider response structure\n",
    "        if \"anthropic\" in model[\"id\"]:\n",
    "            output = result['content'][0]['text'].strip()\n",
    "        elif \"amazon\" in model[\"id\"] and \"embed\" in model[\"id\"]:\n",
    "            return \"Skipped\", \"Embedding model, not applicable for sentiment\"\n",
    "        elif \"amazon\" in model[\"id\"]:\n",
    "            output = result.get('results', [{}])[0].get('outputText', 'Unknown').strip()\n",
    "        elif \"meta\" in model[\"id\"] or \"mistral\" in model[\"id\"]:\n",
    "            output = result.get('generation', result.get('text', 'Unknown')).strip()\n",
    "        elif \"ai21\" in model[\"id\"]:\n",
    "            output = result.get('completions', [{}])[0].get('data', {}).get('text', 'Unknown').strip()\n",
    "        elif \"cohere\" in model[\"id\"] and \"embed\" not in model[\"id\"]:\n",
    "            output = result.get('generations', [{}])[0].get('text', 'Unknown').strip()\n",
    "        else:\n",
    "            output = result.get('text', 'Unknown').strip()\n",
    "\n",
    "        # Validate response\n",
    "        if output in [\"Positive\", \"Negative\"]:\n",
    "            return \"Success\", output\n",
    "        else:\n",
    "            return \"Invalid\", f\"Unexpected output: {output}\"\n",
    "    except ClientError as e:\n",
    "        return \"Error\", str(e)\n",
    "    except Exception as e:\n",
    "        return \"Error\", f\"Unexpected error: {str(e)}\"\n",
    "\n",
    "# Run tests\n",
    "print(\"Testing Bedrock Models (March 5, 2025):\")\n",
    "print(\"-\" * 80)\n",
    "res=[]\n",
    "for model in models_to_test:\n",
    "    status, details = test_model(model)\n",
    "    print(f\"Model: {model['name']:<25} | ID: {model['id']:<40} | Status: {status:<10} | Details: {details}\")\n",
    "    if status == \"Success\":\n",
    "        res.append(model['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:53.699152Z",
     "iopub.status.busy": "2025-03-06T00:54:53.698884Z",
     "iopub.status.idle": "2025-03-06T00:54:53.702300Z",
     "shell.execute_reply": "2025-03-06T00:54:53.701815Z",
     "shell.execute_reply.started": "2025-03-06T00:54:53.699133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models working:\n",
      "['Claude 3 Sonnet', 'Claude 3.5 Sonnet']\n"
     ]
    }
   ],
   "source": [
    "print(\"Models working:\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only 2 models are working which are Claude 3 Sonnet and Claude 3.5 Sonnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select two distinct LLMs (e.g., Claude, LLaMA) for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:31:35.590538Z",
     "iopub.status.busy": "2025-03-05T20:31:35.590166Z",
     "iopub.status.idle": "2025-03-05T20:31:35.593217Z",
     "shell.execute_reply": "2025-03-05T20:31:35.592705Z",
     "shell.execute_reply.started": "2025-03-05T20:31:35.590517Z"
    }
   },
   "source": [
    "### Model 1: Claude 3 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:53.707122Z",
     "iopub.status.busy": "2025-03-06T00:54:53.706960Z",
     "iopub.status.idle": "2025-03-06T00:54:53.711982Z",
     "shell.execute_reply": "2025-03-06T00:54:53.711544Z",
     "shell.execute_reply.started": "2025-03-06T00:54:53.707106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_Prediction\n",
       "Negative    51\n",
       "Positive    49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Claude3_Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:53.712829Z",
     "iopub.status.busy": "2025-03-06T00:54:53.712537Z",
     "iopub.status.idle": "2025-03-06T00:54:53.724654Z",
     "shell.execute_reply": "2025-03-06T00:54:53.724161Z",
     "shell.execute_reply.started": "2025-03-06T00:54:53.712810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.00%\n",
      "Precision: 0.98\n",
      "Recall: 0.96\n",
      "F1-Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T20:35:46.276087Z",
     "iopub.status.busy": "2025-03-05T20:35:46.275832Z",
     "iopub.status.idle": "2025-03-05T20:35:46.278603Z",
     "shell.execute_reply": "2025-03-05T20:35:46.278091Z",
     "shell.execute_reply.started": "2025-03-05T20:35:46.276069Z"
    }
   },
   "source": [
    "### Model 2: Claude 3.5 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:54:53.726703Z",
     "iopub.status.busy": "2025-03-06T00:54:53.726547Z",
     "iopub.status.idle": "2025-03-06T00:55:55.217163Z",
     "shell.execute_reply": "2025-03-06T00:55:55.216548Z",
     "shell.execute_reply.started": "2025-03-06T00:54:53.726688Z"
    }
   },
   "outputs": [],
   "source": [
    "Claude3_5 = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "\n",
    "df1['Claude3_5_Prediction'] = LLM(df1['text'], Claude3_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:55:55.218136Z",
     "iopub.status.busy": "2025-03-06T00:55:55.217877Z",
     "iopub.status.idle": "2025-03-06T00:55:55.223173Z",
     "shell.execute_reply": "2025-03-06T00:55:55.222736Z",
     "shell.execute_reply.started": "2025-03-06T00:55:55.218119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claude3_5_Prediction\n",
       "Positive    50\n",
       "Negative    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Claude3_5_Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:55:55.223971Z",
     "iopub.status.busy": "2025-03-06T00:55:55.223734Z",
     "iopub.status.idle": "2025-03-06T00:55:55.236225Z",
     "shell.execute_reply": "2025-03-06T00:55:55.235754Z",
     "shell.execute_reply.started": "2025-03-06T00:55:55.223955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.00%\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(\"Claude3_5_Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:55:55.238330Z",
     "iopub.status.busy": "2025-03-06T00:55:55.238174Z",
     "iopub.status.idle": "2025-03-06T00:55:55.241403Z",
     "shell.execute_reply": "2025-03-06T00:55:55.240905Z",
     "shell.execute_reply.started": "2025-03-06T00:55:55.238315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Claude3 Predictions:\n",
      "['Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative']\n",
      "\n",
      "All Claude3.5 Predictions:\n",
      "['Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative', 'Negative']\n"
     ]
    }
   ],
   "source": [
    "print(\"All Claude3 Predictions:\")\n",
    "print(df1['Claude3_Prediction'].tolist())\n",
    "\n",
    "print(\"\\nAll Claude3.5 Predictions:\")\n",
    "print(df1['Claude3_5_Prediction'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:55:55.242194Z",
     "iopub.status.busy": "2025-03-06T00:55:55.241972Z",
     "iopub.status.idle": "2025-03-06T00:55:55.248918Z",
     "shell.execute_reply": "2025-03-06T00:55:55.248403Z",
     "shell.execute_reply.started": "2025-03-06T00:55:55.242178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Prediction Counts:\n",
      "          Claude3  Claude3.5\n",
      "Negative       51         50\n",
      "Positive       49         50\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Claude3': df1['Claude3_Prediction'].value_counts(), 'Claude3.5': df1['Claude3_5_Prediction'].value_counts()})\n",
    "print(\"\\nComparison of Prediction Counts:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cell 6 (20%) - Discussion and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare and contrast the performance of zero-shot and few-shot learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-shot learning slightly outperforms zero-shot in my case, leveraging a few examples to achieve near-perfect results (99% accuracy, 1 error) compared to zero-shotâ€™s strong but imperfect performance (97% accuracy, 3 errors). Zero-shot remains highly effective for a no-data scenario, while few-shot excels with minimal supervision, making it the better choice when a small labeled set is feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:33:57.187409Z",
     "iopub.status.busy": "2025-03-06T00:33:57.186793Z",
     "iopub.status.idle": "2025-03-06T00:33:57.190539Z",
     "shell.execute_reply": "2025-03-06T00:33:57.189939Z",
     "shell.execute_reply.started": "2025-03-06T00:33:57.187386Z"
    }
   },
   "source": [
    "### Identify cases where LLM predictions differ from actual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Claude 3 (Zero-Shot):\n",
    "* 1 False Positive: 1 sample predicted \"Positive\" but actually \"Negative\".\n",
    "* 2 False Negatives: 2 samples predicted \"Negative\" but actually \"Positive\".\n",
    "\n",
    "Total: 3 mismatches.\n",
    "\n",
    "#### Claude 3 (Few-Shot):\n",
    "* 1 False Negative: 1 sample predicted \"Negative\" but actually \"Positive\".\n",
    "\n",
    "Total: 1 mismatch.\n",
    "\n",
    "#### Claude 3.5:\n",
    "* 1 False Positive: 1 sample predicted \"Positive\" but actually \"Negative\".\n",
    "* 1 False Negative: 1 sample predicted \"Negative\" but actually \"Positive\".\n",
    "\n",
    "Total: 2 mismatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze potential reasons for misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T01:10:10.719064Z",
     "iopub.status.busy": "2025-03-06T01:10:10.718714Z",
     "iopub.status.idle": "2025-03-06T01:10:10.723689Z",
     "shell.execute_reply": "2025-03-06T01:10:10.722811Z",
     "shell.execute_reply.started": "2025-03-06T01:10:10.719042Z"
    }
   },
   "source": [
    "General reasons for bad model performance:\n",
    "* Ambiguity: Sentiment often depends on context (e.g., \"cool\" can be positive or negative), which LLMs might misjudge without full context.\n",
    "* Sarcasm/Irony: All models may struggle with non-literal language (e.g., \"Great job breaking it\" â†’ Negative).\n",
    "* Data Bias: Training data or few-shot examples might over-represent clear-cut cases, leaving edge cases vulnerable.\n",
    "* Negation Handling: Phrases like \"not terrible\" (Positive) might be misread as Negative due to \"terrible.\"\n",
    "\n",
    "Potential reasons for misclassifications in my models:                                                                    \n",
    "* Claude 3 (Zero-Shot): Misclassifies due to overgeneralization (1 FP) and missing subtle positives (2 FN), inherent to no-data reliance.\n",
    "* Claude 3 (Few-Shot): Minimal errors (1 FN) from unrepresentative examples or edge cases, showing the power of few-shot tuning.\n",
    "* Claude 3.5: Balanced errors (1 FP, 1 FN) suggest refinement but not full immunity to ambiguity or subtlety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T01:12:32.080174Z",
     "iopub.status.busy": "2025-03-06T01:12:32.079837Z",
     "iopub.status.idle": "2025-03-06T01:12:32.083099Z",
     "shell.execute_reply": "2025-03-06T01:12:32.082544Z",
     "shell.execute_reply.started": "2025-03-06T01:12:32.080154Z"
    }
   },
   "source": [
    "### Discuss the differences in outputs from various LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T01:14:31.826624Z",
     "iopub.status.busy": "2025-03-06T01:14:31.826233Z",
     "iopub.status.idle": "2025-03-06T01:14:31.831045Z",
     "shell.execute_reply": "2025-03-06T01:14:31.830380Z",
     "shell.execute_reply.started": "2025-03-06T01:14:31.826602Z"
    }
   },
   "source": [
    "* Claude 3 (Zero-Shot): Outputs are less precise (3 errors), over-predicting negatives and missing positives due to no task-specific tuning.\n",
    "* Claude 3 (Few-Shot): Outputs are the most accurate (1 error), with perfect precision, shaped by example-driven specialization.\n",
    "* Claude 3.5: Outputs improve over zero-shot (2 errors), balancing precision and recall but not matching few-shotâ€™s precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cell 7 (5%) - Acknowledge if you have used any GenAI tools or collaborated with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used Chatgpt and Grok AI for interpretations and to resolve any bugs/errors in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T01:16:09.012058Z",
     "iopub.status.busy": "2025-03-06T01:16:09.011764Z",
     "iopub.status.idle": "2025-03-06T01:16:09.014824Z",
     "shell.execute_reply": "2025-03-06T01:16:09.014283Z",
     "shell.execute_reply.started": "2025-03-06T01:16:09.012039Z"
    }
   },
   "source": [
    "## HTML output (5%) - Convert the notebook to an HTML file ensuring all outputs are visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook LA6_Shah_Rhythm.ipynb to html\n",
      "[NbConvertApp] Writing 416455 bytes to LA6_Shah_Rhythm.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert \"LA6_Shah_Rhythm.ipynb\" --to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
